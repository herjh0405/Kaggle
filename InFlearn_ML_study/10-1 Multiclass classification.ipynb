{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass classification\n",
    "* 중복선택불가\n",
    "* 오렌지, 배, 사과 등\n",
    "* One vs all or One vs One\n",
    "\n",
    "### Multilabel calssification\n",
    "* 상호 배타적이지 않은 속성을 예측\n",
    "* 스포츠/연예/정치 등 -> 야구선수가 연예인과 결혼: 스포츠+연예"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax function\n",
    "* 모든 class의 확률을 1로 Generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax_classifier_with_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "datasets=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data=datasets['data']\n",
    "x_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data=datasets['target']\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data=y_data.reshape([-1,1])\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y_data)  \n",
    "y_data = enc.transform(y_data).toarray()\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_data_minmax = min_max_scaler.fit_transform(x_data)\n",
    "x_data_minmax[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [1.        , 0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [1.        , 0.11111111, 0.5       , 0.05084746, 0.04166667]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x0 추가\n",
    "x_0 =np.ones(x_data_minmax.shape[0])\n",
    "x_data_minmax = np.column_stack((x_0, x_data_minmax))\n",
    "\n",
    "x_data_minmax[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1102529 , 0.745899  , 0.1081304 , 0.97314865, 0.20502714],\n",
       "       [0.93160271, 0.82299433, 0.42295332, 0.16379523, 0.35421825],\n",
       "       [0.43219521, 0.03584577, 0.71318649, 0.98166683, 0.64594675]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.random.uniform(size=(3,5))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    e = np.exp(z)\n",
    "    p = e / np.sum(np.exp(z), axis=1).reshape([-1,1])\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x_data_minmax.dot(weights.T)\n",
    "# x dot theta\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18399401, 0.49348601, 0.32251999],\n",
       "       [0.19575084, 0.48958729, 0.31466186],\n",
       "       [0.18690697, 0.48444368, 0.32864935],\n",
       "       [0.19110203, 0.47461443, 0.33428355],\n",
       "       [0.1803387 , 0.48902036, 0.33064094],\n",
       "       [0.17664947, 0.48830137, 0.33504916],\n",
       "       [0.17996497, 0.47425471, 0.34578031],\n",
       "       [0.18695026, 0.48709389, 0.32595585],\n",
       "       [0.19334546, 0.47218617, 0.33446837],\n",
       "       [0.1959705 , 0.48680699, 0.31722252],\n",
       "       [0.18277432, 0.49958885, 0.31763683],\n",
       "       [0.18611751, 0.47627318, 0.33760931],\n",
       "       [0.19646778, 0.48729063, 0.31624159],\n",
       "       [0.18752474, 0.47948803, 0.33298723],\n",
       "       [0.17484176, 0.52242804, 0.3027302 ],\n",
       "       [0.16445829, 0.50213591, 0.3334058 ],\n",
       "       [0.17194687, 0.5021116 , 0.32594152],\n",
       "       [0.1823425 , 0.49210611, 0.32555139],\n",
       "       [0.18381472, 0.50159069, 0.31459459],\n",
       "       [0.17559845, 0.48621089, 0.33819066],\n",
       "       [0.19347942, 0.49468238, 0.31183819],\n",
       "       [0.17659603, 0.48561013, 0.33779383],\n",
       "       [0.17173272, 0.4877544 , 0.34051287],\n",
       "       [0.18809793, 0.4804937 , 0.33140837],\n",
       "       [0.18973311, 0.46594994, 0.34431696],\n",
       "       [0.19939677, 0.48624987, 0.31435336],\n",
       "       [0.18480237, 0.48087917, 0.33431846],\n",
       "       [0.18621615, 0.49369754, 0.32008631],\n",
       "       [0.18766442, 0.49783594, 0.31449963],\n",
       "       [0.19060267, 0.47410443, 0.3352929 ],\n",
       "       [0.19447428, 0.47845416, 0.32707156],\n",
       "       [0.1875349 , 0.49898598, 0.31347913],\n",
       "       [0.1720067 , 0.49031002, 0.33768328],\n",
       "       [0.16955301, 0.50277685, 0.32767014],\n",
       "       [0.19423841, 0.48551307, 0.32024852],\n",
       "       [0.18861779, 0.49882499, 0.31255722],\n",
       "       [0.18649113, 0.51145469, 0.30205418],\n",
       "       [0.1809944 , 0.4867135 , 0.33229211],\n",
       "       [0.18930702, 0.47489819, 0.33579479],\n",
       "       [0.1879505 , 0.49074982, 0.32129968],\n",
       "       [0.18015065, 0.49185175, 0.32799761],\n",
       "       [0.20865651, 0.48152309, 0.3098204 ],\n",
       "       [0.18379514, 0.47332738, 0.34287748],\n",
       "       [0.17875815, 0.47718918, 0.34405267],\n",
       "       [0.17856637, 0.47094808, 0.35048555],\n",
       "       [0.19300678, 0.48469519, 0.32229802],\n",
       "       [0.17840017, 0.48421917, 0.33738066],\n",
       "       [0.18709921, 0.47731172, 0.33558907],\n",
       "       [0.18181824, 0.49591239, 0.32226937],\n",
       "       [0.1884329 , 0.49125165, 0.32031544],\n",
       "       [0.23587074, 0.43403186, 0.3300974 ],\n",
       "       [0.22307227, 0.41910965, 0.35781808],\n",
       "       [0.23853525, 0.42321169, 0.33825306],\n",
       "       [0.237929  , 0.41216894, 0.34990206],\n",
       "       [0.23898814, 0.42115625, 0.3398556 ],\n",
       "       [0.2304489 , 0.39972312, 0.36982798],\n",
       "       [0.21886495, 0.40701431, 0.37412074],\n",
       "       [0.22335593, 0.41816334, 0.35848072],\n",
       "       [0.24122337, 0.42629855, 0.33247808],\n",
       "       [0.21701272, 0.40157609, 0.38141119],\n",
       "       [0.24066224, 0.4168537 , 0.34248406],\n",
       "       [0.21885407, 0.41291947, 0.36822645],\n",
       "       [0.25472003, 0.4320612 , 0.31321877],\n",
       "       [0.23337612, 0.4049885 , 0.36163538],\n",
       "       [0.21456832, 0.42573109, 0.35970059],\n",
       "       [0.23107886, 0.43450366, 0.33441748],\n",
       "       [0.21810614, 0.39238797, 0.38950589],\n",
       "       [0.23640232, 0.42053365, 0.34306403],\n",
       "       [0.253965  , 0.41670309, 0.3293319 ],\n",
       "       [0.23551504, 0.42027021, 0.34421475],\n",
       "       [0.213272  , 0.38760732, 0.39912068],\n",
       "       [0.2295859 , 0.43016792, 0.34024618],\n",
       "       [0.2505572 , 0.40564879, 0.34379401],\n",
       "       [0.24107641, 0.40779762, 0.35112597],\n",
       "       [0.23437063, 0.42974446, 0.33588491],\n",
       "       [0.23303866, 0.43155308, 0.33540826],\n",
       "       [0.24806199, 0.42540483, 0.32653318],\n",
       "       [0.23619503, 0.41130184, 0.35250313],\n",
       "       [0.22726308, 0.40700523, 0.36573169],\n",
       "       [0.23018951, 0.43787797, 0.33193252],\n",
       "       [0.23612429, 0.42070846, 0.34316725],\n",
       "       [0.23686516, 0.42520625, 0.33792859],\n",
       "       [0.22955211, 0.42495689, 0.345491  ],\n",
       "       [0.23942997, 0.38708824, 0.37348179],\n",
       "       [0.21509586, 0.38531839, 0.39958575],\n",
       "       [0.2090496 , 0.40225802, 0.38869238],\n",
       "       [0.23307635, 0.42321238, 0.34371127],\n",
       "       [0.25478774, 0.42502701, 0.32018524],\n",
       "       [0.2175097 , 0.4082793 , 0.374211  ],\n",
       "       [0.23121198, 0.41118006, 0.35760795],\n",
       "       [0.23511409, 0.3985357 , 0.36635021],\n",
       "       [0.22875646, 0.40776896, 0.36347458],\n",
       "       [0.2341902 , 0.42206351, 0.34374629],\n",
       "       [0.22798779, 0.42217568, 0.34983653],\n",
       "       [0.22855128, 0.40683104, 0.36461768],\n",
       "       [0.22220618, 0.40973931, 0.36805451],\n",
       "       [0.22339611, 0.4091004 , 0.3675035 ],\n",
       "       [0.23166526, 0.42296839, 0.34536635],\n",
       "       [0.21699567, 0.43344005, 0.34956428],\n",
       "       [0.22541477, 0.41304497, 0.36154027],\n",
       "       [0.21431904, 0.35264918, 0.43303179],\n",
       "       [0.22963775, 0.37662899, 0.39373326],\n",
       "       [0.24523353, 0.39027478, 0.36449169],\n",
       "       [0.23897811, 0.37738535, 0.38363655],\n",
       "       [0.23220396, 0.37216644, 0.3956296 ],\n",
       "       [0.26250994, 0.38360438, 0.35388567],\n",
       "       [0.21950831, 0.36889536, 0.41159633],\n",
       "       [0.26420604, 0.38722832, 0.34856564],\n",
       "       [0.26232632, 0.38573247, 0.35194122],\n",
       "       [0.21997014, 0.3785729 , 0.40145695],\n",
       "       [0.22151653, 0.3962518 , 0.38223167],\n",
       "       [0.2415451 , 0.39042162, 0.36803328],\n",
       "       [0.2354917 , 0.3933747 , 0.3711336 ],\n",
       "       [0.23150037, 0.37649183, 0.39200779],\n",
       "       [0.2154361 , 0.3693043 , 0.4152596 ],\n",
       "       [0.21600505, 0.38219315, 0.40180179],\n",
       "       [0.23744641, 0.38681842, 0.37573516],\n",
       "       [0.23465117, 0.37879827, 0.38655056],\n",
       "       [0.27851624, 0.37606021, 0.34542355],\n",
       "       [0.25803886, 0.39363156, 0.34832957],\n",
       "       [0.22834369, 0.38656981, 0.38508651],\n",
       "       [0.21863806, 0.37415185, 0.40721009],\n",
       "       [0.27529882, 0.38496487, 0.33973631],\n",
       "       [0.23707062, 0.40143381, 0.36149557],\n",
       "       [0.226192  , 0.38155184, 0.39225616],\n",
       "       [0.24778443, 0.39276415, 0.35945142],\n",
       "       [0.23092887, 0.40081031, 0.36826082],\n",
       "       [0.22398605, 0.39281477, 0.38319918],\n",
       "       [0.23735641, 0.37771144, 0.38493215],\n",
       "       [0.25663495, 0.40224955, 0.3411155 ],\n",
       "       [0.26429957, 0.39624962, 0.3394508 ],\n",
       "       [0.23841871, 0.39779477, 0.36378652],\n",
       "       [0.23512449, 0.37649287, 0.38838264],\n",
       "       [0.24279256, 0.39779033, 0.35941711],\n",
       "       [0.25554635, 0.37683127, 0.36762238],\n",
       "       [0.25263672, 0.40119146, 0.34617182],\n",
       "       [0.2090528 , 0.36590275, 0.42504446],\n",
       "       [0.2324402 , 0.38284205, 0.38471775],\n",
       "       [0.22129718, 0.39261804, 0.38608477],\n",
       "       [0.2323426 , 0.39952524, 0.36813216],\n",
       "       [0.2252605 , 0.38231756, 0.39242194],\n",
       "       [0.22435433, 0.40702585, 0.36861982],\n",
       "       [0.22963775, 0.37662899, 0.39373326],\n",
       "       [0.22914158, 0.37661497, 0.39424345],\n",
       "       [0.21759327, 0.37628819, 0.40611854],\n",
       "       [0.22596581, 0.39738884, 0.37664534],\n",
       "       [0.24306678, 0.39793315, 0.35900008],\n",
       "       [0.22937532, 0.39423974, 0.37638493],\n",
       "       [0.2074966 , 0.37017416, 0.42232924],\n",
       "       [0.22325615, 0.37931059, 0.39743326]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(z)\n",
    "# 그값을 generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_function(y, x, weights):\n",
    "    z = x_data_minmax.dot(weights.T)\n",
    "    result = - np.sum(\n",
    "                np.sum(\n",
    "                    (y * np.log(softmax(z))), axis=1).reshape((-1,1))\n",
    "                )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176.90579495435293"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_function(y_data,x_data_minmax,weights)\n",
    "# 이 값을 최소화 하고자 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_grdient(y, x, initial_weights, iterations = 500000, alpha=0.001):\n",
    "    cost_history= []\n",
    "    theta_history = []\n",
    "    m = y.shape[0]\n",
    "    theta = np.copy(initial_weights)\n",
    "    \n",
    "    number_of_classes = theta.shape[0]\n",
    "    number_of_weights = theta.shape[1]\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        original_theta = np.copy(theta)\n",
    "        for k in range(number_of_classes):        \n",
    "            for j in range(number_of_weights):\n",
    "                partial_x = x[:, j]\n",
    "                partial_entropy = y - softmax(x.dot(original_theta.T))\n",
    "                theta[k][j]  = original_theta[k][j] + (\n",
    "                    alpha* partial_entropy[:,k].dot(partial_x.T) ) /150\n",
    "        if (_ % 10000) == 0:\n",
    "            print(cross_entropy_function(y,x,theta)/150)\n",
    "            cost_history.append(cross_entropy_function(y,x,theta))\n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1792933483447292\n",
      "0.7758880308163894\n",
      "0.6189202007699005\n",
      "0.5383046507886443\n",
      "0.4877885716400643\n",
      "0.45203629917575616\n",
      "0.4247329106148141\n",
      "0.40280545375761634\n",
      "0.38456502088484207\n",
      "0.36899600294531654\n",
      "0.3554446869287876\n",
      "0.3434675590346096\n",
      "0.332750915934438\n",
      "0.3230652709850799\n",
      "0.31423801874219187\n",
      "0.3061362757223529\n",
      "0.2986556869608357\n",
      "0.2917128828635091\n",
      "0.28524025262574604\n",
      "0.2791822347291961\n",
      "0.27349262839816785\n",
      "0.2681326087114824\n",
      "0.26306923697399404\n",
      "0.2582743262321127\n",
      "0.2537235657408408\n",
      "0.24939583710022523\n",
      "0.24527267420361748\n",
      "0.2413378324353611\n",
      "0.2375769418095058\n",
      "0.2339772252814734\n",
      "0.23052726815196636\n",
      "0.22721682788512698\n",
      "0.2240366761624827\n",
      "0.22097846685043834\n",
      "0.21803462495170076\n",
      "0.21519825266569376\n",
      "0.21246304948893113\n",
      "0.2098232439072152\n",
      "0.20727353471366242\n",
      "0.20480904036367298\n",
      "0.20242525507504852\n",
      "0.20011801061693385\n",
      "0.1978834429191969\n",
      "0.1957179627846207\n",
      "0.19361823010798546\n",
      "0.19158113110485675\n",
      "0.18960375813340968\n",
      "0.18768339175860965\n",
      "0.18581748476239013\n",
      "0.18400364784839787\n"
     ]
    }
   ],
   "source": [
    "# weights = minimize_grdient(y_data, x_data_minmax,weights)\n",
    "theta, cost_history = minimize_grdient(y_data, x_data_minmax,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([139,  19,  87,  53,   7,  16,  82, 127,  26,  49,  53, 143, 104,\n",
       "        89,  36, 117,  52,  48,  58,  90, 121,  34,   9, 140, 127,  41,\n",
       "        48,   2, 120, 140])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rand_index= np.random.randint(0,150,30)\n",
    "rand_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 1, 0, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 2, 1, 0, 1, 1, 2, 0,\n",
       "       0, 2, 2, 0, 0, 0, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(softmax(x_data_minmax[rand_index].dot(theta.T)),axis=1) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 1, 0, 0, 1, 2, 0, 0, 1, 2, 2, 1, 0, 2, 1, 0, 1, 1, 2, 0,\n",
       "       0, 2, 2, 0, 0, 0, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.argmax(y_data[rand_index],axis=1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred == y_true) / len(rand_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
